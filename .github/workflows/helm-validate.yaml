name: Helm Chart Validation

on:
  workflow_call:
    inputs:
      chart_path:
        description: 'Path to the Helm chart directory'
        required: true
        type: string
      kubernetes_version:
        description: 'Target Kubernetes version (e.g., 1.30.0)'
        required: true
        type: string
      scenarios_dir:
        description: 'Path to scenario fixtures (repo-relative)'
        required: false
        type: string
        default: 'tests/scenarios'
      snapshots_dir:
        description: 'Path to snapshot files (repo-relative)'
        required: false
        type: string
        default: 'tests/snapshots'
      run_syntax:
        description: 'Run Layer 1 (syntax + helm lint)'
        required: false
        type: boolean
        default: true
      run_schema:
        description: 'Run Layer 2 (kubeconform over rendered scenarios)'
        required: false
        type: boolean
        default: true
      run_metadata:
        description: 'Run Layer 3 (ct lint + version checks)'
        required: false
        type: boolean
        default: true
      run_tests:
        description: 'Run Layer 4 (unit tests + snapshots + fail-cases)'
        required: false
        type: boolean
        default: true
      run_policy:
        description: 'Run Layer 5 (Checkov + kube-linter)'
        required: false
        type: boolean
        default: true
      target_branch:
        description: 'Base branch for version comparison'
        required: false
        type: string
        default: 'main'
      run_version_check:
        description: 'Run version strictly-greater check'
        required: false
        type: boolean
        default: true
      checkov_extra_args:
        description: 'Extra args for Checkov (e.g., --skip-check CKV_K8S_43)'
        required: false
        type: string
        default: ''
      docker_image:
        description: 'Docker image to use for validation'
        required: false
        type: string
        default: 'ghcr.io/orhayoun-eevee/helm-validate:latest'
      build_workflow_ref:
        description: 'Ref (SHA/tag/branch) of build-workflow to checkout for scripts/configs'
        required: false
        type: string
        default: 'main'
    secrets:
      gh_app_id:
        description: 'GitHub App ID for minting installation token'
        required: true
      gh_app_private_key:
        description: 'GitHub App private key for minting installation token'
        required: true

jobs:
  validate:
    runs-on: ubuntu-latest
    container:
      image: ${{ inputs.docker_image }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0  # Needed for version comparison and ct lint

      - name: Mint app token for cross-repo checkout
        id: app-token
        uses: actions/create-github-app-token@29824e69f54612133e76f7eaac726eef6c875baf # v2.2.1
        with:
          app-id: ${{ secrets.gh_app_id }}
          private-key: ${{ secrets.gh_app_private_key }}
          owner: ${{ github.repository_owner }}

      - name: Checkout build-workflow (validation framework)
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          repository: orhayoun-eevee/build-workflow
          path: .build-workflow
          ref: ${{ inputs.build_workflow_ref }}
          token: ${{ steps.app-token.outputs.token }}

      - name: Resolve chart dependencies
        run: helm dependency build "${{ inputs.chart_path }}"

      - name: Ensure helm-unittest plugin
        run: |
          if ! helm plugin list 2>/dev/null | awk 'NR>1 {print $1}' | grep -qx unittest; then
            helm plugin install https://github.com/helm-unittest/helm-unittest --version v0.8.2
          fi
          helm plugin list

      - name: Run validation pipeline
        env:
          CHART_PATH: ${{ inputs.chart_path }}
          KUBERNETES_VERSION: ${{ inputs.kubernetes_version }}
          SCENARIOS_DIR: ${{ inputs.scenarios_dir }}
          SNAPSHOTS_DIR: ${{ inputs.snapshots_dir }}
          RUN_SYNTAX: ${{ inputs.run_syntax }}
          RUN_SCHEMA: ${{ inputs.run_schema }}
          RUN_METADATA: ${{ inputs.run_metadata }}
          RUN_TESTS: ${{ inputs.run_tests }}
          RUN_POLICY: ${{ inputs.run_policy }}
          TARGET_BRANCH: ${{ inputs.target_branch }}
          RUN_VERSION_CHECK: ${{ inputs.run_version_check }}
          CHECKOV_EXTRA_ARGS: ${{ inputs.checkov_extra_args }}
          CONFIGS_DIR: .build-workflow/configs
        run: .build-workflow/scripts/validate-orchestrator.sh

      - name: Compute quality metrics
        id: quality-metrics
        shell: bash
        run: |
          set -euo pipefail

          CHART_PATH="${{ inputs.chart_path }}"
          SCENARIOS_DIR="${{ inputs.scenarios_dir }}"

          unit_test_files=0
          unit_test_assertions=0
          scenario_count=0
          fail_case_count=0
          checkov_skip_count=0

          if [[ -d "${CHART_PATH}/tests" ]]; then
            unit_test_files=$(find "${CHART_PATH}/tests" -type f -name "*_test.yaml" | wc -l | tr -d ' ')
            unit_test_assertions=$(grep -R -c --include='*_test.yaml' -E '^[[:space:]]*- it:' "${CHART_PATH}/tests" | awk -F: '{sum += $NF} END {print sum + 0}')
          fi

          if [[ -d "${SCENARIOS_DIR}" ]]; then
            scenario_count=$(find "${SCENARIOS_DIR}" -maxdepth 1 -type f -name "*.yaml" | wc -l | tr -d ' ')
          fi

          if [[ -d "${CHART_PATH}/tests/schema-fail-cases" ]]; then
            fail_case_count=$(find "${CHART_PATH}/tests/schema-fail-cases" -maxdepth 1 -type f -name "*.yaml" | wc -l | tr -d ' ')
          fi

          if [[ -f "${CHART_PATH}/.checkov.yaml" ]]; then
            checkov_skip_count=$(grep -c -E '^[[:space:]]*-[[:space:]]*CKV_' "${CHART_PATH}/.checkov.yaml" || true)
          elif [[ -f ".checkov.yaml" ]]; then
            checkov_skip_count=$(grep -c -E '^[[:space:]]*-[[:space:]]*CKV_' ".checkov.yaml" || true)
          fi

          {
            echo "unit_test_files=${unit_test_files}"
            echo "unit_test_assertions=${unit_test_assertions}"
            echo "scenario_count=${scenario_count}"
            echo "fail_case_count=${fail_case_count}"
            echo "checkov_skip_count=${checkov_skip_count}"
          } >> "${GITHUB_OUTPUT}"

          {
            echo "## Validation Quality Metrics"
            echo ""
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| Unit test files | ${unit_test_files} |"
            echo "| Unit test assertions | ${unit_test_assertions} |"
            echo "| Scenarios | ${scenario_count} |"
            echo "| Schema fail-cases | ${fail_case_count} |"
            echo "| Checkov skip rules | ${checkov_skip_count} |"
          } >> "${GITHUB_STEP_SUMMARY}"

      - name: Post PR Comment
        if: always() && github.event_name == 'pull_request'
        continue-on-error: true
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          github-token: ${{ github.token }}
          script: |
            const conclusion = '${{ job.status }}';
            const icon = conclusion === 'success' ? '✅' : '❌';
            const body = [
              `## ${icon} Helm Validation ${conclusion === 'success' ? 'Passed' : 'Failed'}`,
              '',
              `| Setting | Value |`,
              `|---------|-------|`,
              `| Chart | \`${{ inputs.chart_path }}\` |`,
              `| K8s version | \`${{ inputs.kubernetes_version }}\` |`,
              `| Version check | \`${{ inputs.run_version_check }}\` |`,
              `| Unit test files | \`${{ steps.quality-metrics.outputs.unit_test_files }}\` |`,
              `| Unit test assertions | \`${{ steps.quality-metrics.outputs.unit_test_assertions }}\` |`,
              `| Scenarios | \`${{ steps.quality-metrics.outputs.scenario_count }}\` |`,
              `| Schema fail-cases | \`${{ steps.quality-metrics.outputs.fail_case_count }}\` |`,
              `| Checkov skip rules | \`${{ steps.quality-metrics.outputs.checkov_skip_count }}\` |`,
              '',
              `See [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for detailed logs.`
            ].join('\n');

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
