name: Merge CI/CD Flow

# This workflow runs integration tests on a Kind cluster and publishes the Helm chart to OCI registry.
#
# Configuration Options:
# - chart_path: Path to the Helm chart directory (default: '.')
# - values_file: Path to values file for CI (e.g., 'values-ci.yaml'). If not provided, uses default values.yaml (default: '')
#   - Use this to specify CI-specific values that differ from your local development values
#   - The file path is relative to the chart_path directory
# - install_istio: Install full Istio service mesh (default: false)
#   - Installs Istio with CRDs, control plane, and all components
#   - Enables UI access, service mesh routing, and sidecar injection
#   - Setup time: ~3-4 minutes
# - install_prometheus: Install Prometheus Operator/Prometheus (default: false)
#   - Installs Prometheus Operator stack with CRDs, operator, and Prometheus
#   - Enables metrics collection and ServiceMonitor/PodMonitor functionality
#   - Setup time: ~2-3 minutes
# - install_longhorn: Install Longhorn distributed block storage (default: false)
#   - Provides persistent volumes for applications
#   - Setup time: ~2-3 minutes
# - istio_version: Istio version to install (default: '1.20.0')
# - istio_profile: Istio installation profile - ambient, minimal, demo, or default (default: 'ambient')
# - prometheus_chart_version: Prometheus Operator Helm chart version (default: '55.0.0')
# - longhorn_chart_version: Longhorn Helm chart version (default: '1.6.0')
#
# Example Configurations:
# 1. Basic testing (no external services):
#    install_istio: false
#    install_prometheus: false
#    Runtime: ~5 minutes
#    Note: Charts using Istio/Prometheus CRDs will fail unless services are installed
#
# 2. Service mesh testing:
#    install_istio: true
#    install_prometheus: false
#    Runtime: ~8-9 minutes
#
# 3. Metrics testing:
#    install_istio: false
#    install_prometheus: true
#    Runtime: ~7-8 minutes
#
# 4. Full integration:
#    install_istio: true
#    install_prometheus: true
#    Runtime: ~12-15 minutes
#
# Note: Services install their own CRDs when deployed. Install the services your chart requires.

on:
  push:
    branches:
      - main
  workflow_call:
    inputs:
      chart_path:
        description: 'Path to the helm chart directory'
        required: false
        type: string
        default: '.'
      install_istio:
        description: 'Install full Istio service mesh (enables UI access and service mesh functionality)'
        required: false
        type: boolean
        default: false
      install_prometheus:
        description: 'Install Prometheus Operator/Prometheus (enables metrics collection)'
        required: false
        type: boolean
        default: false
      istio_version:
        description: 'Istio version to install (e.g., 1.20.0)'
        required: false
        type: string
        default: '1.20.0'
      istio_profile:
        description: 'Istio installation profile (e.g., ambient, minimal, demo, default)'
        required: false
        type: string
        default: 'ambient'
      prometheus_chart_version:
        description: 'Prometheus Operator Helm chart version (e.g., 55.0.0)'
        required: false
        type: string
        default: '55.0.0'
      install_longhorn:
        description: 'Install Longhorn distributed block storage (provides persistent volumes)'
        required: false
        type: boolean
        default: false
      longhorn_chart_version:
        description: 'Longhorn Helm chart version (e.g., 1.6.0)'
        required: false
        type: string
        default: '1.6.0'
      values_file:
        description: 'Path to values file to use for CI (e.g., values-ci.yaml). If not provided, uses default values.yaml'
        required: false
        type: string
        default: ''

permissions:
  contents: read
  packages: write

jobs:
  integration-test:
    name: Integration Tests with Kind
    runs-on: ubuntu-latest
    steps:
      # Checkout the repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # Install Helm for chart operations
      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      # Install kubectl for Kubernetes operations
      - name: Set up kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      # Install yq for YAML parsing
      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version

      # Create a Kind Kubernetes cluster for testing
      - name: Create Kind cluster
        uses: helm/kind-action@v1
        with:
          cluster_name: test-cluster
          wait: 300s

      # Install Gateway API CRDs (required before Istio if using Gateway API)
      # Gateway API provides standard Kubernetes API for service networking
      # Istio supports Gateway API, so CRDs must be installed first
      - name: Install Gateway API CRDs
        if: ${{ inputs.install_istio == true }}
        run: |
          echo "Installing Gateway API CRDs..."
          
          # Install Gateway API CRDs from official release
          GATEWAY_API_VERSION="1.0.0"
          kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v${GATEWAY_API_VERSION}/standard-install.yaml
          
          # Wait for CRDs to be established
          echo "Waiting for Gateway API CRDs to be established..."
          kubectl wait --for condition=established --timeout=60s \
            crd/gateways.gateway.networking.k8s.io \
            crd/httproutes.gateway.networking.k8s.io \
            crd/referencegrants.gateway.networking.k8s.io \
            crd/gatewayclasses.gateway.networking.k8s.io || true
          
          echo "✓ Gateway API CRDs installed successfully"

      # Install Istio service mesh (if enabled)
      # Installs full Istio with CRDs, control plane, and enables service mesh functionality
      # Enables UI access, routing, and sidecar injection
      # Setup time: ~3-4 minutes
      - name: Install Istio
        if: ${{ inputs.install_istio == true }}
        env:
          ISTIO_VERSION: ${{ inputs.istio_version }}
          ISTIO_PROFILE: ${{ inputs.istio_profile }}
        run: |
          echo "Installing Istio service mesh (version ${ISTIO_VERSION}, profile: ${ISTIO_PROFILE})..."
          
          # Download and install istioctl
          curl -L https://github.com/istio/istio/releases/download/${ISTIO_VERSION}/istio-${ISTIO_VERSION}-linux-amd64.tar.gz | tar -xz
          sudo mv istio-${ISTIO_VERSION}/bin/istioctl /usr/local/bin/
          istioctl version
          
          # Install Istio with specified profile (default: ambient)
          # Ambient profile provides sidecar-less service mesh
          # This installs CRDs, control plane, and all necessary components
          istioctl install --set profile=${ISTIO_PROFILE} -y
          
          # Wait for Istio control plane to be ready
          echo "Waiting for Istio control plane..."
          kubectl wait --for=condition=ready pod -l app=istiod -n istio-system --timeout=300s
          
          # For ambient profile, also wait for ztunnel pods
          if [ "${ISTIO_PROFILE}" = "ambient" ]; then
            echo "Waiting for Istio ambient components (ztunnel)..."
            kubectl wait --for=condition=ready pod -l app=ztunnel -n istio-system --timeout=300s || true
          fi
          
          echo "✓ Istio ${ISTIO_VERSION} (profile: ${ISTIO_PROFILE}) installed successfully (including CRDs)"

      # Install Longhorn (if enabled)
      # Installs Longhorn distributed block storage system
      # Provides persistent volumes for applications
      # Setup time: ~2-3 minutes
      - name: Install Longhorn
        if: ${{ inputs.install_longhorn == true }}
        env:
          LONGHORN_CHART_VERSION: ${{ inputs.longhorn_chart_version }}
        run: |
          echo "Installing Longhorn (chart version ${LONGHORN_CHART_VERSION})..."
          
          # Add Longhorn Helm repository
          helm repo add longhorn https://charts.longhorn.io
          helm repo update
          
          # Install Longhorn
          helm install longhorn longhorn/longhorn \
            --version ${LONGHORN_CHART_VERSION} \
            --namespace longhorn-system \
            --create-namespace \
            --wait \
            --timeout 10m
          
          # Wait for all Longhorn pods to be ready
          echo "Waiting for all Longhorn components to be ready..."
          
          # Wait for Longhorn manager pods
          echo "Waiting for Longhorn manager pods..."
          kubectl wait --for=condition=ready pod \
            -l app=longhorn-manager \
            -n longhorn-system \
            --timeout=300s
          
          # Wait for Longhorn UI pod
          echo "Waiting for Longhorn UI pod..."
          kubectl wait --for=condition=ready pod \
            -l app=longhorn-ui \
            -n longhorn-system \
            --timeout=300s || true
          
          # Wait for Longhorn storage class to be available
          echo "Waiting for Longhorn storage class..."
          for i in {1..30}; do
            if kubectl get storageclass longhorn &>/dev/null; then
              echo "✓ Longhorn storage class is available"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "⚠ Longhorn storage class not found after 30 attempts"
            else
              echo "Waiting for storage class... (attempt $i/30)"
              sleep 2
            fi
          done
          
          # Verify Longhorn system is operational
          echo "Verifying Longhorn system status..."
          # Check that manager pods are running
          MANAGER_READY=$(kubectl get pods -n longhorn-system -l app=longhorn-manager --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
          if [ "$MANAGER_READY" -gt 0 ]; then
            echo "✓ Longhorn manager is running ($MANAGER_READY pod(s))"
          else
            echo "⚠ No Longhorn manager pods in Running state"
          fi
          
          # Wait a bit more for Longhorn to fully initialize
          echo "Allowing Longhorn to fully initialize..."
          sleep 10
          
          echo "✓ Longhorn ${LONGHORN_CHART_VERSION} installed and ready"

      # Install Prometheus (if enabled)
      # Installs full Prometheus Operator stack with CRDs, operator, and Prometheus
      # Enables metrics collection and ServiceMonitor/PodMonitor functionality
      # Setup time: ~2-3 minutes
      - name: Install Prometheus
        if: ${{ inputs.install_prometheus == true }}
        env:
          PROMETHEUS_CHART_VERSION: ${{ inputs.prometheus_chart_version }}
        run: |
          echo "Installing Prometheus Operator stack (chart version ${PROMETHEUS_CHART_VERSION})..."
          
          # Create monitoring namespace
          kubectl create namespace monitoring || true
          
          # Install Prometheus Operator using Helm
          # This installs CRDs, operator, and Prometheus instance
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          
          # Install Prometheus Operator (includes CRDs + operator + Prometheus)
          helm install prometheus prometheus-community/kube-prometheus-stack \
            --version ${PROMETHEUS_CHART_VERSION} \
            --namespace monitoring \
            --set prometheus.prometheusSpec.retention=1h \
            --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=1Gi \
            --wait \
            --timeout 5m
          
          # Wait for Prometheus to be ready
          echo "Waiting for Prometheus to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus -n monitoring --timeout=300s || true
          
          echo "✓ Prometheus Operator stack ${PROMETHEUS_CHART_VERSION} installed successfully (including CRDs)"

      # Set chart path (defaults to '.' if not provided)
      - name: Set chart path
        id: chart_path
        run: |
          CHART_PATH="${{ inputs.chart_path }}"
          if [ -z "$CHART_PATH" ]; then
            CHART_PATH="."
          fi
          echo "path=${CHART_PATH}" >> $GITHUB_OUTPUT
          echo "Using chart path: ${CHART_PATH}"

      # Update Helm chart dependencies
      - name: Update Helm dependencies
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          helm dependency update

      # Extract namespace from chart values (global.namespace) or use default
      - name: Determine namespace
        id: namespace
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          # Try to get namespace from global.namespace in values.yaml
          NAMESPACE=$(yq eval '.global.namespace // ""' values.yaml 2>/dev/null || echo "")
          
          # If not found, try Chart.yaml or default to 'test-ns'
          if [ -z "$NAMESPACE" ]; then
            NAMESPACE="test-ns"
            echo "Using default namespace: ${NAMESPACE}"
          else
            echo "Using namespace from chart values: ${NAMESPACE}"
          fi
          
          echo "namespace=${NAMESPACE}" >> $GITHUB_OUTPUT
          echo "Namespace: ${NAMESPACE}"

      # Create test namespace early so Istio can label it if enabled
      # Uses namespace from chart values (global.namespace) or default
      - name: Create test namespace
        run: |
          kubectl create namespace ${{ steps.namespace.outputs.namespace }} || true
          # Label namespace for Istio injection if Istio is installed
          if [ "${{ inputs.install_istio }}" == "true" ]; then
            kubectl label namespace ${{ steps.namespace.outputs.namespace }} istio-injection=enabled --overwrite || true
            echo "✓ Test namespace labeled for Istio injection"
          fi

      # Install the chart into the namespace from chart values
      - name: Install chart to namespace
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          VALUES_FILE="${{ inputs.values_file }}"
          if [ -n "$VALUES_FILE" ] && [ -f "$VALUES_FILE" ]; then
            echo "Using CI values file: ${VALUES_FILE}"
            helm install myapp . \
              --namespace ${{ steps.namespace.outputs.namespace }} \
              --values ${VALUES_FILE} \
              --wait \
              --timeout 5m
          else
            if [ -n "$VALUES_FILE" ]; then
              echo "⚠️  WARNING: Specified values file '${VALUES_FILE}' not found, using default values.yaml"
            fi
            helm install myapp . \
              --namespace ${{ steps.namespace.outputs.namespace }} \
              --wait \
              --timeout 5m
          fi

      # Wait for all pods to become Ready
      - name: Wait for pods to be Ready
        run: |
          kubectl wait --for=condition=Ready pods \
            --all \
            --namespace ${{ steps.namespace.outputs.namespace }} \
            --timeout=300s

      # Run Helm test suite
      - name: Run helm test
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          helm test myapp --namespace ${{ steps.namespace.outputs.namespace }}

      # Conditional tests based on installed services
      # Test UI access if Istio is installed
      # Verifies that Istio Gateway and VirtualService resources are properly configured
      - name: Test UI access (Istio)
        if: ${{ inputs.install_istio == true }}
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          echo "=== Testing Istio integration in namespace: ${NAMESPACE} ==="
          # Verify Gateway resources exist
          GATEWAYS=$(kubectl get gateway -n ${NAMESPACE} --no-headers 2>/dev/null | wc -l)
          if [ "$GATEWAYS" -gt 0 ]; then
            echo "✓ Found $GATEWAYS Gateway resource(s)"
            kubectl get gateway -n ${NAMESPACE}
          else
            echo "⚠ No Gateway resources found in ${NAMESPACE} namespace"
          fi
          
          # Verify VirtualService resources exist
          VIRTUAL_SERVICES=$(kubectl get virtualservice -n ${NAMESPACE} --no-headers 2>/dev/null | wc -l)
          if [ "$VIRTUAL_SERVICES" -gt 0 ]; then
            echo "✓ Found $VIRTUAL_SERVICES VirtualService resource(s)"
            kubectl get virtualservice -n ${NAMESPACE}
          else
            echo "⚠ No VirtualService resources found in ${NAMESPACE} namespace"
          fi
          
          # Verify Istio sidecars are injected
          SIDECARS=$(kubectl get pods -n ${NAMESPACE} -o jsonpath='{.items[*].spec.containers[*].name}' | grep -o istio-proxy | wc -l || echo "0")
          if [ "$SIDECARS" -gt 0 ]; then
            echo "✓ Istio sidecars detected in pods"
          else
            echo "⚠ No Istio sidecars detected (may be expected if injection is disabled)"
          fi
          
          echo "=== Istio integration test complete ==="

      # Test metrics endpoints if Prometheus is installed
      # Verifies that ServiceMonitor/PodMonitor resources are configured and Prometheus can discover targets
      - name: Test metrics endpoints (Prometheus)
        if: ${{ inputs.install_prometheus == true }}
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          echo "=== Testing Prometheus integration in namespace: ${NAMESPACE} ==="
          # Verify ServiceMonitor resources exist
          SERVICEMONITORS=$(kubectl get servicemonitor -n ${NAMESPACE} --no-headers 2>/dev/null | wc -l)
          if [ "$SERVICEMONITORS" -gt 0 ]; then
            echo "✓ Found $SERVICEMONITORS ServiceMonitor resource(s)"
            kubectl get servicemonitor -n ${NAMESPACE}
          else
            echo "⚠ No ServiceMonitor resources found in ${NAMESPACE} namespace"
          fi
          
          # Verify PodMonitor resources exist
          PODMONITORS=$(kubectl get podmonitor -n ${NAMESPACE} --no-headers 2>/dev/null | wc -l)
          if [ "$PODMONITORS" -gt 0 ]; then
            echo "✓ Found $PODMONITORS PodMonitor resource(s)"
            kubectl get podmonitor -n ${NAMESPACE}
          else
            echo "⚠ No PodMonitor resources found in ${NAMESPACE} namespace"
          fi
          
          # Verify Prometheus can discover targets (if Prometheus pod exists)
          PROM_POD=$(kubectl get pod -n monitoring -l app.kubernetes.io/name=prometheus -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$PROM_POD" ]; then
            echo "Checking Prometheus target discovery..."
            if kubectl exec -n monitoring "$PROM_POD" -- wget -qO- http://localhost:9090/api/v1/targets 2>/dev/null | grep -q "activeTargets"; then
              echo "✓ Prometheus is discovering targets"
            else
              echo "⚠ Prometheus has no active targets (may be expected if no ServiceMonitors configured)"
            fi
          else
            echo "⚠ Prometheus pod not found, skipping target discovery check"
          fi
          
          echo "=== Prometheus integration test complete ==="

      # Upgrade test: Install previous version and upgrade to current
      - name: Upgrade test - Install previous version
        working-directory: ${{ steps.chart_path.outputs.path }}
        env:
          # CONFIGURATION: Set these in GitHub repository Settings > Secrets and variables > Actions > Variables
          # HELM_REPO_URL: URL of your Helm repository (e.g., https://charts.example.com or oci://ghcr.io/owner)
          # PREVIOUS_CHART_VERSION: Previous version to install before upgrading (e.g., 1.0.0)
          # CHART_NAME: Name of the chart in the repo (defaults to chart name from Chart.yaml)
          HELM_REPO_URL: ${{ vars.HELM_REPO_URL }}
          PREVIOUS_CHART_VERSION: ${{ vars.PREVIOUS_CHART_VERSION }}
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          # Clean up the initial installation
          helm uninstall myapp --namespace ${NAMESPACE} || true
          kubectl delete namespace ${NAMESPACE} || true
          kubectl create namespace ${NAMESPACE} || true
          
          # Get chart name from Chart.yaml
          CHART_NAME=$(yq eval '.name' Chart.yaml)
          
          # Check if upgrade test is configured
          VALUES_FILE="${{ inputs.values_file }}"
          VALUES_FLAG=""
          if [ -n "$VALUES_FILE" ] && [ -f "$VALUES_FILE" ]; then
            VALUES_FLAG="--values ${VALUES_FILE}"
            echo "Using CI values file: ${VALUES_FILE}"
          fi
          
          if [ -z "$HELM_REPO_URL" ] || [ -z "$PREVIOUS_CHART_VERSION" ]; then
            echo "⚠️  WARNING: Upgrade test skipped - HELM_REPO_URL or PREVIOUS_CHART_VERSION not configured"
            echo "⚠️  To enable upgrade testing, set these in: Settings > Secrets and variables > Actions > Variables"
            echo "⚠️  HELM_REPO_URL: Your Helm repository URL (e.g., https://charts.example.com)"
            echo "⚠️  PREVIOUS_CHART_VERSION: Previous chart version to test upgrade from (e.g., 1.0.0)"
            echo "⚠️  Installing current chart as fallback for basic functionality test"
            helm install myapp . \
              --namespace ${NAMESPACE} \
              ${VALUES_FLAG} \
              --wait \
              --timeout 5m
          else
            echo "✓ Upgrade test configured: Installing previous version $PREVIOUS_CHART_VERSION from $HELM_REPO_URL"
            
            # Add Helm repository
            helm repo add upgrade-test-repo "$HELM_REPO_URL" || {
              echo "❌ ERROR: Failed to add Helm repository: $HELM_REPO_URL"
              exit 1
            }
            helm repo update upgrade-test-repo
            
            # Install previous version
            # Note: CI values file may not exist in previous version, so we try to use it but don't fail if it doesn't
            if [ -n "$VALUES_FLAG" ] && [ -f "$VALUES_FILE" ]; then
              echo "Attempting to install previous version with CI values file..."
              helm install myapp upgrade-test-repo/$CHART_NAME \
                --version "$PREVIOUS_CHART_VERSION" \
                --namespace ${NAMESPACE} \
                ${VALUES_FLAG} \
                --wait \
                --timeout 5m || {
                echo "⚠️  WARNING: Failed to install previous version with CI values, trying without..."
                helm install myapp upgrade-test-repo/$CHART_NAME \
                  --version "$PREVIOUS_CHART_VERSION" \
                  --namespace ${NAMESPACE} \
                  --wait \
                  --timeout 5m || {
                  echo "❌ ERROR: Failed to install previous version $PREVIOUS_CHART_VERSION"
                  exit 1
                }
              }
            else
              helm install myapp upgrade-test-repo/$CHART_NAME \
                --version "$PREVIOUS_CHART_VERSION" \
                --namespace ${NAMESPACE} \
                --wait \
                --timeout 5m || {
                echo "❌ ERROR: Failed to install previous version $PREVIOUS_CHART_VERSION"
                exit 1
              }
            fi
            
            echo "✓ Previous version installed successfully"
          fi

      # Upgrade to current chart version
      - name: Upgrade test - Upgrade to current version
        working-directory: ${{ steps.chart_path.outputs.path }}
        env:
          PREVIOUS_CHART_VERSION: ${{ vars.PREVIOUS_CHART_VERSION }}
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          VALUES_FILE="${{ inputs.values_file }}"
          VALUES_FLAG=""
          if [ -n "$VALUES_FILE" ] && [ -f "$VALUES_FILE" ]; then
            VALUES_FLAG="--values ${VALUES_FILE}"
            echo "Using CI values file: ${VALUES_FILE}"
          fi
          
          # Only run upgrade if previous version was installed
          if [ -n "$PREVIOUS_CHART_VERSION" ]; then
            echo "✓ Upgrading from $PREVIOUS_CHART_VERSION to current version"
            helm upgrade myapp . \
              --namespace ${NAMESPACE} \
              ${VALUES_FLAG} \
              --wait \
              --timeout 5m \
              --reuse-values
            echo "✓ Upgrade completed successfully"
          else
            echo "⚠️  Skipping upgrade step (previous version not configured)"
          fi

      # Verify pods are still Ready after upgrade
      - name: Wait for pods after upgrade
        env:
          PREVIOUS_CHART_VERSION: ${{ vars.PREVIOUS_CHART_VERSION }}
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          # Only wait if upgrade was performed
          if [ -n "$PREVIOUS_CHART_VERSION" ]; then
            kubectl wait --for=condition=Ready pods \
              --all \
              --namespace ${NAMESPACE} \
              --timeout=300s
          else
            echo "⚠️  Skipping pod wait (upgrade test not configured)"
          fi

      # Debug information on failure
      - name: Debug - Get pods status
        if: failure()
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          echo "=== Pod Status in namespace: ${NAMESPACE} ==="
          kubectl get pods -n ${NAMESPACE} -o wide

      - name: Debug - Describe pods
        if: failure()
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          echo "=== Pod Details in namespace: ${NAMESPACE} ==="
          kubectl get pods -n ${NAMESPACE} -o name | xargs -I {} kubectl describe {} -n ${NAMESPACE}

      - name: Debug - Get events
        if: failure()
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          echo "=== Events in namespace: ${NAMESPACE} ==="
          kubectl get events -n ${NAMESPACE} --sort-by='.lastTimestamp'

      - name: Debug - Helm release status
        if: failure()
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          echo "=== Helm Release Status in namespace: ${NAMESPACE} ==="
          helm status myapp --namespace ${NAMESPACE} || true
          helm history myapp --namespace ${NAMESPACE} || true

      - name: Debug - Get all resources
        if: failure()
        run: |
          NAMESPACE="${{ steps.namespace.outputs.namespace }}"
          echo "=== All Resources in namespace: ${NAMESPACE} ==="
          kubectl get all -n ${NAMESPACE}

  publish:
    name: Publish Helm Chart to OCI
    needs: integration-test
    runs-on: ubuntu-latest
    steps:
      # Checkout the repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # Install Helm for packaging and pushing
      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      # Install yq for YAML parsing
      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version

      # Set chart path (defaults to '.' if not provided)
      - name: Set chart path
        id: chart_path
        run: |
          CHART_PATH="${{ inputs.chart_path }}"
          if [ -z "$CHART_PATH" ]; then
            CHART_PATH="."
          fi
          echo "path=${CHART_PATH}" >> $GITHUB_OUTPUT
          echo "Using chart path: ${CHART_PATH}"

      # Login to GitHub Container Registry
      - name: Login to registry
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | helm registry login ghcr.io \
            --username ${{ github.repository_owner }} \
            --password-stdin

      # Extract chart version and git SHA for tagging
      - name: Extract chart version and git SHA
        id: metadata
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          CHART_VERSION=$(yq eval '.version' Chart.yaml)
          GIT_SHA=$(git rev-parse --short HEAD)
          FULL_VERSION="${CHART_VERSION}-${GIT_SHA}"
          echo "chart_version=${CHART_VERSION}" >> $GITHUB_OUTPUT
          echo "git_sha=${GIT_SHA}" >> $GITHUB_OUTPUT
          echo "full_version=${FULL_VERSION}" >> $GITHUB_OUTPUT
          echo "Chart version: ${CHART_VERSION}"
          echo "Git SHA: ${GIT_SHA}"
          echo "Full version: ${FULL_VERSION}"

      # Package the Helm chart
      - name: Package Helm chart
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          helm package . --version ${{ steps.metadata.outputs.full_version }}

      # Push the packaged chart to OCI registry
      - name: Push chart to OCI registry
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          CHART_NAME=$(yq eval '.name' Chart.yaml)
          PACKAGE_FILE="${CHART_NAME}-${{ steps.metadata.outputs.full_version }}.tgz"
          helm push ${PACKAGE_FILE} oci://ghcr.io/${{ github.repository_owner }}
