name: Merge CI/CD Flow

# This workflow runs integration tests on a Kind cluster and publishes the Helm chart to OCI registry.
#
# Configuration Options:
# - chart_path: Path to the Helm chart directory (default: '.')
# - install_istio: Install full Istio service mesh (default: false)
#   - Installs Istio with CRDs, control plane, and all components
#   - Enables UI access, service mesh routing, and sidecar injection
#   - Setup time: ~3-4 minutes
# - install_prometheus: Install Prometheus Operator/Prometheus (default: false)
#   - Installs Prometheus Operator stack with CRDs, operator, and Prometheus
#   - Enables metrics collection and ServiceMonitor/PodMonitor functionality
#   - Setup time: ~2-3 minutes
# - istio_version: Istio version to install (default: '1.20.0')
# - prometheus_chart_version: Prometheus Operator Helm chart version (default: '55.0.0')
#
# Example Configurations:
# 1. Basic testing (no external services):
#    install_istio: false
#    install_prometheus: false
#    Runtime: ~5 minutes
#    Note: Charts using Istio/Prometheus CRDs will fail unless services are installed
#
# 2. Service mesh testing:
#    install_istio: true
#    install_prometheus: false
#    Runtime: ~8-9 minutes
#
# 3. Metrics testing:
#    install_istio: false
#    install_prometheus: true
#    Runtime: ~7-8 minutes
#
# 4. Full integration:
#    install_istio: true
#    install_prometheus: true
#    Runtime: ~12-15 minutes
#
# Note: Services install their own CRDs when deployed. Install the services your chart requires.

on:
  push:
    branches:
      - main
  workflow_call:
    inputs:
      chart_path:
        description: 'Path to the helm chart directory'
        required: false
        type: string
        default: '.'
      install_istio:
        description: 'Install full Istio service mesh (enables UI access and service mesh functionality)'
        required: false
        type: boolean
        default: false
      install_prometheus:
        description: 'Install Prometheus Operator/Prometheus (enables metrics collection)'
        required: false
        type: boolean
        default: false
      istio_version:
        description: 'Istio version to install (e.g., 1.20.0)'
        required: false
        type: string
        default: '1.20.0'
      prometheus_chart_version:
        description: 'Prometheus Operator Helm chart version (e.g., 55.0.0)'
        required: false
        type: string
        default: '55.0.0'

permissions:
  contents: read
  packages: write

jobs:
  integration-test:
    name: Integration Tests with Kind
    runs-on: ubuntu-latest
    steps:
      # Checkout the repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # Install Helm for chart operations
      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      # Install kubectl for Kubernetes operations
      - name: Set up kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      # Install yq for YAML parsing
      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version

      # Create a Kind Kubernetes cluster for testing
      - name: Create Kind cluster
        uses: helm/kind-action@v1
        with:
          cluster_name: test-cluster
          wait: 300s

      # Install Gateway API CRDs (required before Istio if using Gateway API)
      # Gateway API provides standard Kubernetes API for service networking
      # Istio supports Gateway API, so CRDs must be installed first
      - name: Install Gateway API CRDs
        if: ${{ inputs.install_istio == true }}
        run: |
          echo "Installing Gateway API CRDs..."
          
          # Install Gateway API CRDs from official release
          GATEWAY_API_VERSION="1.0.0"
          kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v${GATEWAY_API_VERSION}/standard-install.yaml
          
          # Wait for CRDs to be established
          echo "Waiting for Gateway API CRDs to be established..."
          kubectl wait --for condition=established --timeout=60s \
            crd/gateways.gateway.networking.k8s.io \
            crd/httproutes.gateway.networking.k8s.io \
            crd/referencegrants.gateway.networking.k8s.io \
            crd/gatewayclasses.gateway.networking.k8s.io || true
          
          echo "✓ Gateway API CRDs installed successfully"

      # Install Istio service mesh (if enabled)
      # Installs full Istio with CRDs, control plane, and enables service mesh functionality
      # Enables UI access, routing, and sidecar injection
      # Setup time: ~3-4 minutes
      - name: Install Istio
        if: ${{ inputs.install_istio == true }}
        env:
          ISTIO_VERSION: ${{ inputs.istio_version }}
        run: |
          echo "Installing Istio service mesh (version ${ISTIO_VERSION})..."
          
          # Download and install istioctl
          curl -L https://github.com/istio/istio/releases/download/${ISTIO_VERSION}/istio-${ISTIO_VERSION}-linux-amd64.tar.gz | tar -xz
          sudo mv istio-${ISTIO_VERSION}/bin/istioctl /usr/local/bin/
          istioctl version
          
          # Install Istio with minimal profile for faster setup
          # This installs CRDs, control plane, and all necessary components
          istioctl install --set profile=minimal -y
          
          # Wait for Istio control plane to be ready
          echo "Waiting for Istio control plane..."
          kubectl wait --for=condition=ready pod -l app=istiod -n istio-system --timeout=300s
          
          echo "✓ Istio ${ISTIO_VERSION} installed successfully (including CRDs)"

      # Install Prometheus (if enabled)
      # Installs full Prometheus Operator stack with CRDs, operator, and Prometheus
      # Enables metrics collection and ServiceMonitor/PodMonitor functionality
      # Setup time: ~2-3 minutes
      - name: Install Prometheus
        if: ${{ inputs.install_prometheus == true }}
        env:
          PROMETHEUS_CHART_VERSION: ${{ inputs.prometheus_chart_version }}
        run: |
          echo "Installing Prometheus Operator stack (chart version ${PROMETHEUS_CHART_VERSION})..."
          
          # Create monitoring namespace
          kubectl create namespace monitoring || true
          
          # Install Prometheus Operator using Helm
          # This installs CRDs, operator, and Prometheus instance
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          
          # Install Prometheus Operator (includes CRDs + operator + Prometheus)
          helm install prometheus prometheus-community/kube-prometheus-stack \
            --version ${PROMETHEUS_CHART_VERSION} \
            --namespace monitoring \
            --set prometheus.prometheusSpec.retention=1h \
            --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=1Gi \
            --wait \
            --timeout 5m
          
          # Wait for Prometheus to be ready
          echo "Waiting for Prometheus to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus -n monitoring --timeout=300s || true
          
          echo "✓ Prometheus Operator stack ${PROMETHEUS_CHART_VERSION} installed successfully (including CRDs)"

      # Create test namespace early so Istio can label it if enabled
      - name: Create test namespace
        run: |
          kubectl create namespace test-ns || true
          # Label namespace for Istio injection if Istio is installed
          if [ "${{ inputs.install_istio }}" == "true" ]; then
            kubectl label namespace test-ns istio-injection=enabled --overwrite || true
            echo "✓ Test namespace labeled for Istio injection"
          fi

      # Set chart path (defaults to '.' if not provided)
      - name: Set chart path
        id: chart_path
        run: |
          CHART_PATH="${{ inputs.chart_path }}"
          if [ -z "$CHART_PATH" ]; then
            CHART_PATH="."
          fi
          echo "path=${CHART_PATH}" >> $GITHUB_OUTPUT
          echo "Using chart path: ${CHART_PATH}"

      # Update Helm chart dependencies
      - name: Update Helm dependencies
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          helm dependency update

      # Install the chart into a test namespace
      # Note: Namespace is created earlier to allow Istio labeling if enabled
      - name: Install chart to test namespace
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          helm install myapp . \
            --namespace test-ns \
            --wait \
            --timeout 5m

      # Wait for all pods to become Ready
      - name: Wait for pods to be Ready
        run: |
          kubectl wait --for=condition=Ready pods \
            --all \
            --namespace test-ns \
            --timeout=300s

      # Run Helm test suite
      - name: Run helm test
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          helm test myapp --namespace test-ns

      # Conditional tests based on installed services
      # Test UI access if Istio is installed
      # Verifies that Istio Gateway and VirtualService resources are properly configured
      - name: Test UI access (Istio)
        if: ${{ inputs.install_istio == true }}
        run: |
          echo "=== Testing Istio integration ==="
          # Verify Gateway resources exist
          GATEWAYS=$(kubectl get gateway -n test-ns --no-headers 2>/dev/null | wc -l)
          if [ "$GATEWAYS" -gt 0 ]; then
            echo "✓ Found $GATEWAYS Gateway resource(s)"
            kubectl get gateway -n test-ns
          else
            echo "⚠ No Gateway resources found in test-ns namespace"
          fi
          
          # Verify VirtualService resources exist
          VIRTUAL_SERVICES=$(kubectl get virtualservice -n test-ns --no-headers 2>/dev/null | wc -l)
          if [ "$VIRTUAL_SERVICES" -gt 0 ]; then
            echo "✓ Found $VIRTUAL_SERVICES VirtualService resource(s)"
            kubectl get virtualservice -n test-ns
          else
            echo "⚠ No VirtualService resources found in test-ns namespace"
          fi
          
          # Verify Istio sidecars are injected
          SIDECARS=$(kubectl get pods -n test-ns -o jsonpath='{.items[*].spec.containers[*].name}' | grep -o istio-proxy | wc -l || echo "0")
          if [ "$SIDECARS" -gt 0 ]; then
            echo "✓ Istio sidecars detected in pods"
          else
            echo "⚠ No Istio sidecars detected (may be expected if injection is disabled)"
          fi
          
          echo "=== Istio integration test complete ==="

      # Test metrics endpoints if Prometheus is installed
      # Verifies that ServiceMonitor/PodMonitor resources are configured and Prometheus can discover targets
      - name: Test metrics endpoints (Prometheus)
        if: ${{ inputs.install_prometheus == true }}
        run: |
          echo "=== Testing Prometheus integration ==="
          # Verify ServiceMonitor resources exist
          SERVICEMONITORS=$(kubectl get servicemonitor -n test-ns --no-headers 2>/dev/null | wc -l)
          if [ "$SERVICEMONITORS" -gt 0 ]; then
            echo "✓ Found $SERVICEMONITORS ServiceMonitor resource(s)"
            kubectl get servicemonitor -n test-ns
          else
            echo "⚠ No ServiceMonitor resources found in test-ns namespace"
          fi
          
          # Verify PodMonitor resources exist
          PODMONITORS=$(kubectl get podmonitor -n test-ns --no-headers 2>/dev/null | wc -l)
          if [ "$PODMONITORS" -gt 0 ]; then
            echo "✓ Found $PODMONITORS PodMonitor resource(s)"
            kubectl get podmonitor -n test-ns
          else
            echo "⚠ No PodMonitor resources found in test-ns namespace"
          fi
          
          # Verify Prometheus can discover targets (if Prometheus pod exists)
          PROM_POD=$(kubectl get pod -n monitoring -l app.kubernetes.io/name=prometheus -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$PROM_POD" ]; then
            echo "Checking Prometheus target discovery..."
            if kubectl exec -n monitoring "$PROM_POD" -- wget -qO- http://localhost:9090/api/v1/targets 2>/dev/null | grep -q "activeTargets"; then
              echo "✓ Prometheus is discovering targets"
            else
              echo "⚠ Prometheus has no active targets (may be expected if no ServiceMonitors configured)"
            fi
          else
            echo "⚠ Prometheus pod not found, skipping target discovery check"
          fi
          
          echo "=== Prometheus integration test complete ==="

      # Upgrade test: Install previous version and upgrade to current
      - name: Upgrade test - Install previous version
        working-directory: ${{ steps.chart_path.outputs.path }}
        env:
          # CONFIGURATION: Set these in GitHub repository Settings > Secrets and variables > Actions > Variables
          # HELM_REPO_URL: URL of your Helm repository (e.g., https://charts.example.com or oci://ghcr.io/owner)
          # PREVIOUS_CHART_VERSION: Previous version to install before upgrading (e.g., 1.0.0)
          # CHART_NAME: Name of the chart in the repo (defaults to chart name from Chart.yaml)
          HELM_REPO_URL: ${{ vars.HELM_REPO_URL }}
          PREVIOUS_CHART_VERSION: ${{ vars.PREVIOUS_CHART_VERSION }}
        run: |
          # Clean up the initial installation
          helm uninstall myapp --namespace test-ns || true
          kubectl delete namespace test-ns || true
          kubectl create namespace test-ns || true
          
          # Get chart name from Chart.yaml
          CHART_NAME=$(yq eval '.name' Chart.yaml)
          
          # Check if upgrade test is configured
          if [ -z "$HELM_REPO_URL" ] || [ -z "$PREVIOUS_CHART_VERSION" ]; then
            echo "⚠️  WARNING: Upgrade test skipped - HELM_REPO_URL or PREVIOUS_CHART_VERSION not configured"
            echo "⚠️  To enable upgrade testing, set these in: Settings > Secrets and variables > Actions > Variables"
            echo "⚠️  HELM_REPO_URL: Your Helm repository URL (e.g., https://charts.example.com)"
            echo "⚠️  PREVIOUS_CHART_VERSION: Previous chart version to test upgrade from (e.g., 1.0.0)"
            echo "⚠️  Installing current chart as fallback for basic functionality test"
            helm install myapp . \
              --namespace test-ns \
              --wait \
              --timeout 5m
          else
            echo "✓ Upgrade test configured: Installing previous version $PREVIOUS_CHART_VERSION from $HELM_REPO_URL"
            
            # Add Helm repository
            helm repo add upgrade-test-repo "$HELM_REPO_URL" || {
              echo "❌ ERROR: Failed to add Helm repository: $HELM_REPO_URL"
              exit 1
            }
            helm repo update upgrade-test-repo
            
            # Install previous version
            helm install myapp upgrade-test-repo/$CHART_NAME \
              --version "$PREVIOUS_CHART_VERSION" \
              --namespace test-ns \
              --wait \
              --timeout 5m || {
              echo "❌ ERROR: Failed to install previous version $PREVIOUS_CHART_VERSION"
              exit 1
            }
            
            echo "✓ Previous version installed successfully"
          fi

      # Upgrade to current chart version
      - name: Upgrade test - Upgrade to current version
        working-directory: ${{ steps.chart_path.outputs.path }}
        env:
          PREVIOUS_CHART_VERSION: ${{ vars.PREVIOUS_CHART_VERSION }}
        run: |
          # Only run upgrade if previous version was installed
          if [ -n "$PREVIOUS_CHART_VERSION" ]; then
            echo "✓ Upgrading from $PREVIOUS_CHART_VERSION to current version"
            helm upgrade myapp . \
              --namespace test-ns \
              --wait \
              --timeout 5m \
              --reuse-values
            echo "✓ Upgrade completed successfully"
          else
            echo "⚠️  Skipping upgrade step (previous version not configured)"
          fi

      # Verify pods are still Ready after upgrade
      - name: Wait for pods after upgrade
        env:
          PREVIOUS_CHART_VERSION: ${{ vars.PREVIOUS_CHART_VERSION }}
        run: |
          # Only wait if upgrade was performed
          if [ -n "$PREVIOUS_CHART_VERSION" ]; then
            kubectl wait --for=condition=Ready pods \
              --all \
              --namespace test-ns \
              --timeout=300s
          else
            echo "⚠️  Skipping pod wait (upgrade test not configured)"
          fi

      # Debug information on failure
      - name: Debug - Get pods status
        if: failure()
        run: |
          echo "=== Pod Status ==="
          kubectl get pods -n test-ns -o wide

      - name: Debug - Describe pods
        if: failure()
        run: |
          echo "=== Pod Details ==="
          kubectl get pods -n test-ns -o name | xargs -I {} kubectl describe {} -n test-ns

      - name: Debug - Get events
        if: failure()
        run: |
          echo "=== Events ==="
          kubectl get events -n test-ns --sort-by='.lastTimestamp'

      - name: Debug - Helm release status
        if: failure()
        run: |
          echo "=== Helm Release Status ==="
          helm status myapp --namespace test-ns || true
          helm history myapp --namespace test-ns || true

      - name: Debug - Get all resources
        if: failure()
        run: |
          echo "=== All Resources in Namespace ==="
          kubectl get all -n test-ns

  publish:
    name: Publish Helm Chart to OCI
    needs: integration-test
    runs-on: ubuntu-latest
    steps:
      # Checkout the repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # Install Helm for packaging and pushing
      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      # Install yq for YAML parsing
      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version

      # Set chart path (defaults to '.' if not provided)
      - name: Set chart path
        id: chart_path
        run: |
          CHART_PATH="${{ inputs.chart_path }}"
          if [ -z "$CHART_PATH" ]; then
            CHART_PATH="."
          fi
          echo "path=${CHART_PATH}" >> $GITHUB_OUTPUT
          echo "Using chart path: ${CHART_PATH}"

      # Login to GitHub Container Registry
      - name: Login to registry
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | helm registry login ghcr.io \
            --username ${{ github.repository_owner }} \
            --password-stdin

      # Extract chart version and git SHA for tagging
      - name: Extract chart version and git SHA
        id: metadata
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          CHART_VERSION=$(yq eval '.version' Chart.yaml)
          GIT_SHA=$(git rev-parse --short HEAD)
          FULL_VERSION="${CHART_VERSION}-${GIT_SHA}"
          echo "chart_version=${CHART_VERSION}" >> $GITHUB_OUTPUT
          echo "git_sha=${GIT_SHA}" >> $GITHUB_OUTPUT
          echo "full_version=${FULL_VERSION}" >> $GITHUB_OUTPUT
          echo "Chart version: ${CHART_VERSION}"
          echo "Git SHA: ${GIT_SHA}"
          echo "Full version: ${FULL_VERSION}"

      # Package the Helm chart
      - name: Package Helm chart
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          helm package . --version ${{ steps.metadata.outputs.full_version }}

      # Push the packaged chart to OCI registry
      - name: Push chart to OCI registry
        working-directory: ${{ steps.chart_path.outputs.path }}
        run: |
          CHART_NAME=$(yq eval '.name' Chart.yaml)
          PACKAGE_FILE="${CHART_NAME}-${{ steps.metadata.outputs.full_version }}.tgz"
          helm push ${PACKAGE_FILE} oci://ghcr.io/${{ github.repository_owner }}
